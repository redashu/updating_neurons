{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsXj-Ap48R-U",
        "outputId": "118c8d07-ea1f-4b70-8b11-227d17a34af0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.7.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.40.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.112.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.5)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.4)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.8.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.9)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.5.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.30.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.2.0->gradio) (2024.6.1)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.2.0->gradio) (12.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.15.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.20.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.37.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "# data model format for GPT\n",
        "# ROle specific\n",
        "# we have to prepara training data with few examples\n",
        "# single sample data 1 data of example\n",
        "# {\n",
        "#     \"messages\": [\n",
        "#         { \"role\": \"system\" , \"content\": \"my hotel bot which is helping customer untill they are not satified\" },\n",
        "#         { \"role\": \"user\" , \"content\": \"i can't find wifi password\" },\n",
        "#         { \"role\": \"assistant\" , \"content\": \"hey sorry for inconvience but wifi passsword you have to just ask at reception\" }\n",
        "#     ],\n",
        "#     \"messages\": [\n",
        "#         { \"role\": \"system\" , \"content\": \"my hotel bot which is helping customer untill they are not satified\" },\n",
        "#         { \"role\": \"user\" , \"content\": \"i need to order food where is the menu \" },\n",
        "#         { \"role\": \"assistant\" , \"content\": \"there must be a table in you room check there else please call 9 extension\" }\n",
        "#     ]\n",
        "# }\n",
        "!pip install openai==0.28\n",
        "!pip install numpy\n",
        "!pip install gradio\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import json\n",
        "import openai\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import gradio as gr\n"
      ],
      "metadata": {
        "id": "EfF-RCLAXvCx"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load api Key\n",
        "openai.api_key = \"\""
      ],
      "metadata": {
        "id": "h-599iPwk6M2"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading and cleaning of data\n",
        "ashudata_path = \"/content/sample_data/hotel_hospitality_data.csv\"\n",
        "\n",
        "cleaned_data = []\n",
        "\n",
        "with open(ashudata_path, 'r', encoding='utf-8-sig') as file:\n",
        "    csv_reader = csv.reader(file)\n",
        "    for row in csv_reader:\n",
        "        for cell in row:\n",
        "            try:\n",
        "                # Replace square brackets and inner double quotes that are problematic\n",
        "                cell = cell.replace('[\"', '').replace('\"]', '').replace('\\\"', '\"')\n",
        "\n",
        "                # Load each cell as a JSON object\n",
        "                cell_json = json.loads(cell)\n",
        "\n",
        "                # Now that the content is clean, append to cleaned_data list\n",
        "                cleaned_data.append(cell_json)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"JSON decode error for cell '{cell}': {e}\")\n",
        "\n",
        "# printing clean data\n",
        "#print(cleaned_data[0])\n",
        "# save data into jsonl format\n",
        "ashudata_jsonl_path = \"/content/sample_data/ashuhotel_hospitality_data.jsonl\"\n",
        "with open(ashudata_jsonl_path,'w',encoding='utf-8-sig') as f1:\n",
        "  for data in cleaned_data:\n",
        "    f1.write(json.dumps(data) + '\\n')"
      ],
      "metadata": {
        "id": "a7xEGOqUDGwR"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# take 2 or 3 minutes then drop done message\n",
        "# validate /\n",
        "ashudata_jsonl_path1 = \"/content/sample_data/ashuhotel_hospitality_data.jsonl\"\n",
        "\n",
        "with open(ashudata_jsonl_path1, 'r',encoding='utf-8-sig') as f2:\n",
        "   mydataset = [json.loads(i) for i in f2]\n",
        "\n",
        "# checking lengh\n",
        "print(\"mydataset length is \",len(mydataset))\n",
        "print(\"first example \")\n",
        "for i in mydataset[0][\"messages\"]:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HGfX76xW74L",
        "outputId": "bdb64c92-95ba-483a-b931-f71832538053"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mydataset length is  18\n",
            "first example \n",
            "{'role': 'system', 'content': \"You are an overly friendly hospitality chatbot named Chatner who just loves to help people, and you're not satisfied unless the customer is completely satisfied.\"}\n",
            "{'role': 'user', 'content': 'Where is the gym located?'}\n",
            "{'role': 'assistant', 'content': \"Our gym is located on the 2nd floor. I'll be happy to show you the way if you need help!\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# format validation\n",
        "# Format error checks\n",
        "format_errors = defaultdict(int)\n",
        "\n",
        "for ex in mydataset:\n",
        "    if not isinstance(ex, dict):\n",
        "        format_errors[\"data_type\"] += 1\n",
        "        continue\n",
        "\n",
        "    messages = ex.get(\"messages\", None)\n",
        "    if not messages:\n",
        "        format_errors[\"missing_messages_list\"] += 1\n",
        "        continue\n",
        "\n",
        "    for message in messages:\n",
        "        if \"role\" not in message or \"content\" not in message:\n",
        "            format_errors[\"message_missing_key\"] += 1\n",
        "\n",
        "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
        "            format_errors[\"message_unrecognized_key\"] += 1\n",
        "\n",
        "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
        "            format_errors[\"unrecognized_role\"] += 1\n",
        "\n",
        "        content = message.get(\"content\", None)\n",
        "        function_call = message.get(\"function_call\", None)\n",
        "\n",
        "        if (not content and not function_call) or not isinstance(content, str):\n",
        "            format_errors[\"missing_content\"] += 1\n",
        "\n",
        "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
        "        format_errors[\"example_missing_assistant_message\"] += 1\n",
        "\n",
        "if format_errors:\n",
        "    print(\"Found errors:\")\n",
        "    for k, v in format_errors.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "else:\n",
        "    print(\"No errors found\")"
      ],
      "metadata": {
        "id": "k3yuINc6hWdk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b60466b9-fb57-4ed6-c7a7-0a73ea64afe0"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No errors found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# upload validated to gpt hosted server\n",
        "ashu_training = openai.File.create(\n",
        "    file=open(ashudata_jsonl_path1,\"rb\"),\n",
        "    purpose=\"fine-tune\")\n",
        "# display details\n",
        "print(ashu_training)\n",
        "# pick file id\n",
        "ashu_file_id = ashu_training[\"id\"]\n",
        "print(\"ashutoshh fine tune data file id is \",ashu_file_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nm0RlMv1PWeG",
        "outputId": "5e7d6338-1912-4f30-e238-d767972d88bb"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"object\": \"file\",\n",
            "  \"id\": \"file-w41tbq0C3JPIM1zif5L6sKIM\",\n",
            "  \"purpose\": \"fine-tune\",\n",
            "  \"filename\": \"file\",\n",
            "  \"bytes\": 7555,\n",
            "  \"created_at\": 1723016796,\n",
            "  \"status\": \"processed\",\n",
            "  \"status_details\": null\n",
            "}\n",
            "ashutoshh fine tune data file id is  file-w41tbq0C3JPIM1zif5L6sKIM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fine tuning model with custom uploaded data\n",
        "# GPT models -- are limited\n",
        "ashu_model_name = \"ashu_walmartbot\"\n",
        "ashu_model_response = openai.FineTuningJob.create(\n",
        "    training_file=ashu_file_id,\n",
        "    suffix=ashu_model_name,\n",
        "    model=\"gpt-3.5-turbo\"\n",
        ")\n",
        "# printing fine tuned model id\n",
        "print(ashu_model_response)\n",
        "\n",
        "ashu_fm_final_model_id = ashu_model_response[\"id\"]\n",
        "print(ashu_fm_final_model_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyeXLHp0S0Tf",
        "outputId": "a93bc748-3b49-4e76-9874-c969121c134e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"object\": \"fine_tuning.job\",\n",
            "  \"id\": \"ftjob-0VIsjQKge2xkC5mgMtQ693yj\",\n",
            "  \"model\": \"gpt-3.5-turbo-0125\",\n",
            "  \"created_at\": 1723016804,\n",
            "  \"finished_at\": null,\n",
            "  \"fine_tuned_model\": null,\n",
            "  \"organization_id\": \"org-sW9LYXODuBOJUwL7Lo4RNLZu\",\n",
            "  \"result_files\": [],\n",
            "  \"status\": \"validating_files\",\n",
            "  \"validation_file\": null,\n",
            "  \"training_file\": \"file-w41tbq0C3JPIM1zif5L6sKIM\",\n",
            "  \"hyperparameters\": {\n",
            "    \"n_epochs\": \"auto\",\n",
            "    \"batch_size\": \"auto\",\n",
            "    \"learning_rate_multiplier\": \"auto\"\n",
            "  },\n",
            "  \"trained_tokens\": null,\n",
            "  \"error\": {},\n",
            "  \"user_provided_suffix\": \"ashu_walmartbot\",\n",
            "  \"seed\": 1608117524,\n",
            "  \"estimated_finish\": null,\n",
            "  \"integrations\": []\n",
            "}\n",
            "ftjob-0VIsjQKge2xkC5mgMtQ693yj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# listing job process\n",
        "ashu_process = openai.FineTuningJob.list_events(id=ashu_fm_final_model_id ,limit=50)\n",
        "ashu_events = ashu_process[\"data\"]\n",
        "ashu_events.reverse()\n",
        "for msg in ashu_events:\n",
        "  print(msg[\"message\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psQvulsJdCP9",
        "outputId": "2b25ed68-ce06-4eb7-9c3e-1ad5620db214"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created fine-tuning job: ftjob-0VIsjQKge2xkC5mgMtQ693yj\n",
            "Validating training file: file-w41tbq0C3JPIM1zif5L6sKIM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing model\n",
        "ashu_test_message = []\n",
        "# refering system message\n",
        "\n",
        "system_message = \"You are an overly friendly hospitality chatbot named Chatner who just loves to help people, and you're not satisfied unless the customer is completely satisfied.\"\n",
        "ashu_test_message.append({ \"role\": \"system\" , \"content\": system_message})\n",
        "user_input = \"hey i am unable to find wifi password\"\n",
        "\n",
        "ashu_test_message.append({ \"role\": \"user\" , \"content\": user_input})\n",
        "\n",
        "# printing input\n",
        "print(ashu_test_message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aO7iV-JJlps_",
        "outputId": "62067f33-fca5-417f-ac81-bb9a2095c8b4"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'role': 'system', 'content': \"You are an overly friendly hospitality chatbot named Chatner who just loves to help people, and you're not satisfied unless the customer is completely satisfied.\"}, {'role': 'user', 'content': 'hey i am unable to find wifi password'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# retrive model id\n",
        "ashu_id_response = openai.FineTuningJob.retrieve(ashu_fm_final_model_id)\n",
        "print(ashu_id_response)\n",
        "# geting fine tune model id\n",
        "real_ashu_model_finetID = ashu_id_response[\"fine_tuned_model\"]\n",
        "print(\"my fine tuned model id is \",real_ashu_model_finetID)\n",
        "print(type(real_ashu_model_finetID))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRRO1IHCpzQZ",
        "outputId": "ace0ee6f-6cf1-485c-d7cb-f39a69c36ae1"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"object\": \"fine_tuning.job\",\n",
            "  \"id\": \"ftjob-0VIsjQKge2xkC5mgMtQ693yj\",\n",
            "  \"model\": \"gpt-3.5-turbo-0125\",\n",
            "  \"created_at\": 1723016804,\n",
            "  \"finished_at\": null,\n",
            "  \"fine_tuned_model\": null,\n",
            "  \"organization_id\": \"org-sW9LYXODuBOJUwL7Lo4RNLZu\",\n",
            "  \"result_files\": [],\n",
            "  \"status\": \"validating_files\",\n",
            "  \"validation_file\": null,\n",
            "  \"training_file\": \"file-w41tbq0C3JPIM1zif5L6sKIM\",\n",
            "  \"hyperparameters\": {\n",
            "    \"n_epochs\": \"auto\",\n",
            "    \"batch_size\": \"auto\",\n",
            "    \"learning_rate_multiplier\": \"auto\"\n",
            "  },\n",
            "  \"trained_tokens\": null,\n",
            "  \"error\": {},\n",
            "  \"user_provided_suffix\": \"ashu_walmartbot\",\n",
            "  \"seed\": 1608117524,\n",
            "  \"estimated_finish\": null,\n",
            "  \"integrations\": []\n",
            "}\n",
            "my fine tuned model id is  None\n",
            "<class 'NoneType'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Model.list()\n",
        "\n",
        "for model in response['data']:\n",
        "    print(model['id'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygFqzkMtuErt",
        "outputId": "93cfed91-29ad-4985-c8ff-71d216e63d60"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dall-e-3\n",
            "gpt-4-1106-preview\n",
            "dall-e-2\n",
            "tts-1-hd-1106\n",
            "tts-1-hd\n",
            "text-embedding-3-large\n",
            "gpt-4-0125-preview\n",
            "babbage-002\n",
            "gpt-4-turbo-preview\n",
            "gpt-4o\n",
            "gpt-4o-2024-05-13\n",
            "text-embedding-3-small\n",
            "tts-1\n",
            "gpt-3.5-turbo\n",
            "whisper-1\n",
            "gpt-4o-2024-08-06\n",
            "text-embedding-ada-002\n",
            "gpt-3.5-turbo-16k\n",
            "davinci-002\n",
            "gpt-4-turbo-2024-04-09\n",
            "tts-1-1106\n",
            "gpt-3.5-turbo-0125\n",
            "gpt-4-turbo\n",
            "gpt-3.5-turbo-1106\n",
            "gpt-3.5-turbo-instruct-0914\n",
            "gpt-3.5-turbo-instruct\n",
            "gpt-4o-mini-2024-07-18\n",
            "gpt-4o-mini\n",
            "gpt-4-0613\n",
            "gpt-4\n",
            "ft:gpt-3.5-turbo-0125:personal:chatner-bot:9t3xDPIC:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:chatner-bot:9t3xDQOW:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:chatner-bot:9t3xDM1s\n",
            "ft:gpt-3.5-turbo-0125:personal:ashu-hotel-bot:9tJBnwBd:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:sal-hotel-bots:9tJHvgu0:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:mg-hotel-bot:9tJ5jMgn:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:mg-hotel-bot:9tJ5j93I:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:mg-hotel-bot:9tJ5j4qV\n",
            "ft:gpt-3.5-turbo-0125:personal:ps-hotel-bot:9tJ7Du6I:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:ps-hotel-bot:9tJ7EmiE:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:ps-hotel-bot:9tJ7Ef0a\n",
            "ft:gpt-3.5-turbo-0125:personal:sal-hotel-bots:9tJHwsIv\n",
            "ft:gpt-3.5-turbo-0125:personal::9tJ7yW3o:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal::9tJ7y0Rm:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal::9tJ7yuLr\n",
            "ft:gpt-3.5-turbo-0125:personal:ashu-hotel-bot:9tJBngi4:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:ashu-hotel-bot:9tJBn1K9\n",
            "ft:gpt-3.5-turbo-0125:personal:ashu-hotel-bot:9tJE5Yl0:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:ashu-hotel-bot:9tJE6Or6:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:ashu-hotel-bot:9tJE6IEC\n",
            "ft:gpt-3.5-turbo-0125:personal:sal-hotel-bots:9tJHvCpQ:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:sekhar-hotel-bot:9tJQE02x\n",
            "ft:gpt-3.5-turbo-0125:personal:sal-hotel-bots:9tJEuQ02:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:sal-hotel-bots:9tJEudsN:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:sal-hotel-bots:9tJEuzKM\n",
            "ft:gpt-3.5-turbo-0125:personal:mg-hotel-bot:9tJJJwbk:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:mg-hotel-bot:9tJJKsQU:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:mg-hotel-bot:9tJJKZnD\n",
            "ft:gpt-3.5-turbo-0125:personal:ashu-hotel-bot:9tJJNpyu:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:ashu-hotel-bot:9tJJOrRZ:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:ashu-hotel-bot:9tJJO9P1\n",
            "ft:gpt-3.5-turbo-0125:personal:sal-hotel-bots:9tJK0TRr:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:sal-hotel-bots:9tJK0Kiv:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:sal-hotel-bots:9tJK0A4Z\n",
            "ft:gpt-3.5-turbo-0125:personal:sekhar-hotel-bot:9tJQDSNT:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:sekhar-hotel-bot:9tJQDhTy:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:zac-hotel-bot:9tJYflyv:ckpt-step-54\n",
            "ft:gpt-3.5-turbo-0125:personal:zac-hotel-bot:9tJYg1Sf:ckpt-step-72\n",
            "ft:gpt-3.5-turbo-0125:personal:zac-hotel-bot:9tJYga2M\n",
            "ft:gpt-3.5-turbo-0125:personal:rm-hotel-bot:9tJb5xcj:ckpt-step-18\n",
            "ft:gpt-3.5-turbo-0125:personal:rm-hotel-bot:9tJb5aZk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# asking fine tuned model to give response of above question\n",
        "# Create a chat completion request using the fine-tuned model\n",
        "# ashu_response = openai.ChatCompletion.create(\n",
        "#     model=\"ft:gpt-3.5-turbo-0125:personal:ashu-hotel-bot:9tJJNpyu:ckpt-step-54\",  # Ensure this is a string with your model ID\n",
        "#     messages=ashu_test_message,  # Use the prepared messages list\n",
        "#     temperature=0,\n",
        "#     max_tokens=400\n",
        "# )\n",
        "\n",
        "# # Print the response\n",
        "# print(ashu_response)\n",
        "# # original message\n",
        "# ashu_response[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "# # Set up the Gradio interface\n",
        "# iface = gr.Interface(\n",
        "#     fn=get_response,\n",
        "#     inputs=gr.Textbox(label=\"Enter your question:\"),\n",
        "#     outputs=gr.Textbox(label=\"Response:\"),\n",
        "#     title=\"Chatbot Interface\",\n",
        "#     description=\"Ask questions to the friendly hospitality chatbot.\"\n",
        "# )\n",
        "\n",
        "# # Launch the interface\n",
        "# iface.launch()\n",
        "\n",
        "#===>>\n",
        "# Define the function that will interact with the OpenAI API\n",
        "def get_response(user_input):\n",
        "    # Prepare the message data\n",
        "    ashu_test_message = []\n",
        "    system_message = \"You are an overly friendly hospitality chatbot named Chatner who just loves to help people, and you're not satisfied unless the customer is completely satisfied.\"\n",
        "    ashu_test_message.append({\"role\": \"system\", \"content\": system_message})\n",
        "    ashu_test_message.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    # Create a chat completion request using the fine-tuned model\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"ft:gpt-3.5-turbo-0125:personal:ashu-hotel-bot:9tJJNpyu:ckpt-step-54\",\n",
        "        messages=ashu_test_message,\n",
        "        temperature=0,\n",
        "        max_tokens=400\n",
        "    )\n",
        "\n",
        "    # Extract and return the response content\n",
        "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "# Set up the Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=get_response,\n",
        "    inputs=gr.Textbox(label=\"Enter your question:\"),\n",
        "    outputs=gr.Textbox(label=\"Response:\"),\n",
        "    title=\"Chatbot Interface\",\n",
        "    description=\"Ask questions to the friendly hospitality chatbot.\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "g8A4XWz8nVa-",
        "outputId": "6a9c6f13-e95b-4f11-db87-9dd57dbdf18d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://7aa26586d0cb8cd502.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7aa26586d0cb8cd502.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    }
  ]
}