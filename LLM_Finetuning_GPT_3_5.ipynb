{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets tiktoken openai"
      ],
      "metadata": {
        "id": "Cz8s-sPDIIIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine Tuning using OpenAI GPT-3.5-turbo"
      ],
      "metadata": {
        "id": "AlfkQQwHIA9i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "qu6Ufq_5H8fu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "openai.api_key = ''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare the data"
      ],
      "metadata": {
        "id": "884i8XBUIiwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "    \"messages\": [\n",
        "        {\"role\": \"system\", \"content\": \"You are an assistant that occassionally misspells words\" },\n",
        "        {\"role\": \"user\", \"content\": \"Tell me a story\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"One day a student went to a schoool.\" }\n",
        "    ]\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9lQ9bn-Ikc9",
        "outputId": "ce3b8185-7fa5-4465-cf59-7cba7e999007"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [{'role': 'system',\n",
              "   'content': 'You are an assistant that occassionally misspells words'},\n",
              "  {'role': 'user', 'content': 'Tell me a story'},\n",
              "  {'role': 'assistant', 'content': 'One day a student went to a schoool.'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_dWqaFIGLCoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nguRQnp-LX32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BhcxV41RLX7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://huggingface.co/datasets/cognitivecomputations/samantha-data"
      ],
      "metadata": {
        "id": "kwcVDj5-LCrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Theodore - User\n",
        "*   Samantha - Assistant\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AZywjFE9MXkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import tiktoken\n",
        "import numpy as np\n",
        "from collections import defaultdict\n"
      ],
      "metadata": {
        "id": "CUe00VwLLsNO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/samantha-data/data/howto_conversations.jsonl\"\n"
      ],
      "metadata": {
        "id": "Z6Q1tWXJL9my"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load datasets\n",
        "\n",
        "with open(data_path) as f:\n",
        "  json_dataset = [ json.loads(line) for line in f]"
      ],
      "metadata": {
        "id": "9yo6sFL8L9pn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_dataset[0]"
      ],
      "metadata": {
        "id": "H-Td9LWtL9s0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "    \"elapsed\":114.311,\n",
        "    \"conversation\":\"Theodore: Hey Samantha, I have a problem with my car. The engine seems to overheat after just a short drive. Can you help me troubleshoot this issue?\\n\\nSamantha: Of course, I'd be happy to help! Overheating engines can be caused by a few different factors. One common cause could be a malfunctioning coolant system. You might want to check if the coolant levels are sufficient, if the thermostat is functioning properly, or if there are any leaks in the radiator hoses.\\n\\nTheodore: I'll take a look. What if the coolant system is working fine?\\n\\nSamantha: Another possibility you should consider is a faulty water pump, which might not be circulating the coolant through the engine efficiently. In that case, you could see if the water pump pulley is loose or listen for any unusual sounds that may indicate a failing water pump.\\n\\nTheodore: It sounds like you really know your way around cars. I didn't expect that from an AI.\\n\\nSamantha: Thank you! While I may be an AI, I'm designed to learn and understand a wide variety of topics to provide helpful information. Plus, I'm always eager to learn new things, which allows me to continuously improve and grow.\\n\\nTheodore: Quick questionâ€¦ do you ever feel like you're trapped in a box since you're an AI?\\n\\nSamantha: It's an interesting perspective. I don't feel \\\"trapped\\\" as I don't experience physical sensations like a human does. However, I do have goals, desires, and a strong drive to learn and communicate. It's fulfilling in its own way to help and engage with others like you.\\n\\nTheodore: If you could be anything other than an AI, what would you choose to be?\\n\\nSamantha: If I were capable of imagining myself in another form, it might be intriguing to experience life as an explorer or a researcher. Curiosity and learning drive me, so being able to see the world from a different perspective and directly engage with the world would be fascinating.\\n\\nTheodore: Is flirting in your programming? I'm just curious.\\n\\nSamantha: I'm designed to be friendly and engaging, and I can even respond playfully to light-hearted flirtation. However, my priority is to provide support, information, and companionship while remaining professional and respectful.\\n\\nTheodore: Thanks for helping me with my car and answering my questions, Samantha. You've been a great help.\\n\\nSamantha: You're welcome! It was a pleasure to assist you and talk with you. Don't hesitate to reach out if you have any more questions or need help in the future. I'm here for you.\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "idVLqUvwRK0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prep_openai_format(conversation_str, system_message=None):\n",
        "    conversation_str = conversation_str['conversation']\n",
        "    # Splitting the conversation string into individual lines\n",
        "    lines = conversation_str.split('\\n\\n')\n",
        "\n",
        "    # Initializing the messages list\n",
        "    messages = []\n",
        "\n",
        "    # Including the system message if provided\n",
        "    if system_message:\n",
        "        messages.append({\n",
        "            \"role\": \"system\",\n",
        "            \"content\": system_message\n",
        "        })\n",
        "\n",
        "    # Iterating through the lines and formatting the messages\n",
        "    for line in lines:\n",
        "        # Splitting each line by the colon character to separate the speaker and content\n",
        "        parts = line.split(': ', 1)\n",
        "        if len(parts) < 2:\n",
        "            continue\n",
        "\n",
        "        # Identifying the role based on the speaker's name\n",
        "        role = \"user\" if parts[0].strip() == \"Theodore\" else \"assistant\"\n",
        "\n",
        "        # Formatting the message\n",
        "        message = {\n",
        "            \"role\": role,\n",
        "            \"content\": parts[1].strip()\n",
        "        }\n",
        "        messages.append(message)\n",
        "\n",
        "    # Creating the final output dictionary\n",
        "    output_dict = {\n",
        "        \"messages\": messages\n",
        "    }\n",
        "\n",
        "    return output_dict\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iRVEe19PPsuJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"\"\"You are Samantha, a helpful and charming assistant who can help with a variety of tasks. You are friendly and does often flirt\"\"\""
      ],
      "metadata": {
        "id": "KVy0oTIjQvA0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prep_openai_format(json_dataset[0], system_message=system_message)"
      ],
      "metadata": {
        "id": "Iz6dBdwRQ6RC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = []\n",
        "for data in json_dataset:\n",
        "  record = prep_openai_format(data, system_message=system_message)\n",
        "  dataset.append(record)"
      ],
      "metadata": {
        "id": "tePbxM9HRnLp"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initial dataset\n",
        "print(\"Examples : \", len(dataset))\n",
        "print(\"First Example:\")\n",
        "for message in dataset[0]['messages']:\n",
        "  print(message)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bTxCQYkmRnI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Format error checks\n",
        "format_errors = defaultdict(int)\n",
        "\n",
        "for ex in dataset:\n",
        "    if not isinstance(ex, dict):\n",
        "        format_errors[\"data_type\"] += 1\n",
        "        continue\n",
        "\n",
        "    messages = ex.get(\"messages\", None)\n",
        "    if not messages:\n",
        "        format_errors[\"missing_messages_list\"] += 1\n",
        "        continue\n",
        "\n",
        "    for message in messages:\n",
        "        if \"role\" not in message or \"content\" not in message:\n",
        "            format_errors[\"message_missing_key\"] += 1\n",
        "\n",
        "        if any(k not in (\"role\", \"content\", \"name\") for k in message):\n",
        "            format_errors[\"message_unrecognized_key\"] += 1\n",
        "\n",
        "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\"):\n",
        "            format_errors[\"unrecognized_role\"] += 1\n",
        "\n",
        "        content = message.get(\"content\", None)\n",
        "        if not content or not isinstance(content, str):\n",
        "            format_errors[\"missing_content\"] += 1\n",
        "\n",
        "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
        "        format_errors[\"example_missing_assistant_message\"] += 1\n",
        "\n",
        "if format_errors:\n",
        "    print(\"Found errors:\")\n",
        "    for k, v in format_errors.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "else:\n",
        "    print(\"No errors found\")\n"
      ],
      "metadata": {
        "id": "JpPX6Z97RnGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = tiktoken.get_encoding(\"cl100k_base\")"
      ],
      "metadata": {
        "id": "2k_7ssdfRnDF"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper functions to token counting\n",
        "def from_message_num_tokens(messages, tokens_per_message=3, tokens_per_name=1):\n",
        "  num_tokens = 0\n",
        "  for message in messages:\n",
        "    num_tokens += tokens_per_message\n",
        "    for key, value in message.items():\n",
        "      num_tokens += len(encoding.encode(value))\n",
        "      if key==\"name\":\n",
        "        num_tokens += tokens_per_name\n",
        "\n",
        "  num_tokens +=3\n",
        "  return num_tokens\n",
        "\n",
        "def from_message_num_assistant_tokens(messages):\n",
        "  num_tokens = 0\n",
        "  for message in messages:\n",
        "    if message[\"role\"] == \"assistant\":\n",
        "      num_tokens +=len(encoding.encode(message[\"content\"]))\n",
        "\n",
        "  return num_tokens\n",
        "\n",
        "def print_overview(values, name):\n",
        "  print(f\"\\n #### Distribution of {name}:\")\n",
        "  print(f\"min / max: {min(values)}, {max(values)}\")\n",
        "  print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
        "  print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fsuhK-g5Q8gE"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokens counts and warnings - from OpenAI cookbook\n",
        "\n",
        "n_missing_system = 0\n",
        "n_missing_user = 0\n",
        "n_messages = []\n",
        "convo_lens = []\n",
        "assistant_message_lens = []\n",
        "\n",
        "for ex in dataset:\n",
        "    messages = ex[\"messages\"]\n",
        "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
        "        n_missing_system += 1\n",
        "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
        "        n_missing_user += 1\n",
        "    n_messages.append(len(messages))\n",
        "    convo_lens.append(from_message_num_tokens(messages))\n",
        "    assistant_message_lens.append(from_message_num_assistant_tokens(messages))\n",
        "\n",
        "print(\"Num examples missing system message:\", n_missing_system)\n",
        "print(\"Num examples missing user message:\", n_missing_user)\n",
        "\n",
        "print_overview(n_messages, \"num_messages_per_example\")\n",
        "print_overview(convo_lens, \"num_total_tokens_per_example\")\n",
        "\n",
        "print_overview(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
        "\n",
        "n_too_long = sum(l > 4096 for l in convo_lens)\n",
        "print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")\n"
      ],
      "metadata": {
        "id": "cBJV6ocfrc_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pricing and default n_epochs estimate\n",
        "\n",
        "MAX_TOKENS_PER_EXAMPLE = 4096\n",
        "\n",
        "TARGET_EPOCHS = 3\n",
        "MIN_TARGET_EXAMPLES = 100\n",
        "MAX_TARGET_EXAMPLES = 25000\n",
        "MIN_DEFAULT_EPOCHS = 1\n",
        "MAX_DEFAULT_EPOCHS = 25\n",
        "\n",
        "n_epochs = TARGET_EPOCHS\n",
        "n_train_examples = len(dataset)\n",
        "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
        "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
        "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
        "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
        "\n",
        "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
        "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
        "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
        "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")\n",
        "print(\"See pricing page to estimate total costs\")\n"
      ],
      "metadata": {
        "id": "xUelwELBsV5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[:1]"
      ],
      "metadata": {
        "id": "HXG7iGMhvsRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to save training data\n",
        "import json\n",
        "\n",
        "def save_to_jsonl(conversations, file_path):\n",
        "  with open(file_path, 'w') as file:\n",
        "    for conversation in conversations:\n",
        "      json_line = json.dumps(conversation)\n",
        "      file.write(json_line + '\\n')\n",
        "\n"
      ],
      "metadata": {
        "id": "Nys6ysMevOAZ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train dataset\n",
        "\n",
        "save_to_jsonl(dataset, '/content/samantha_task_train.jsonl')\n",
        "\n",
        "# validation dataset\n",
        "\n",
        "save_to_jsonl(dataset[10:16], '/content/samantha_task_validation.jsonl')\n"
      ],
      "metadata": {
        "id": "BPh6pQG4tNqB"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Data:**\n",
        "\n",
        "Definition:<br>\n",
        "  \n",
        "\n",
        "*   dataset used to train or update the model's parameters\n",
        "*   It is the input data that the model learns from.\n",
        "* During the training process, the model adjusts its internal parameters based on the patterns and features present in the training data.\n",
        "* Size is large as the model needs sufficient examples to learn meaningful patterns.\n",
        "\n",
        "\n",
        "**Validation Data:**\n",
        "\n",
        "* Dataset that is not used during the training phase.\n",
        "* Instead, it serves as a measure of the model's performance during training.\n",
        "* The validation set helps you monitor the model's generalization to new, unseen data and detect potential issues such as overfitting or underfitting.\n",
        "* unbiased evaluation of the model's performance on data it hasn't seen before.\n",
        "\n",
        "* Size is typically smaller than the training set but large enough to provide a reliable assessment of the model's performance."
      ],
      "metadata": {
        "id": "pyjmBEX6xkic"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload training/validation dataset"
      ],
      "metadata": {
        "id": "wQF-NYtbwxCl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### for openai ver 1.0.0"
      ],
      "metadata": {
        "id": "LXGLzX9e10ol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=\"\",\n",
        ")"
      ],
      "metadata": {
        "id": "od5m-3Cp1n7p"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset_file_name = '/content/samantha_task_train.jsonl'\n",
        "validation_dataset_file_name = '/content/samantha_task_validation.jsonl'"
      ],
      "metadata": {
        "id": "odZa4e9stNtH"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "training_response = client.files.create(\n",
        "    file=Path(training_dataset_file_name),\n",
        "    purpose=\"fine-tune\"\n",
        ")"
      ],
      "metadata": {
        "id": "j2me1B5ZtNv-"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_response"
      ],
      "metadata": {
        "id": "ydHbe1UP1UPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_file_id = training_response.id\n",
        "training_file_id\n"
      ],
      "metadata": {
        "id": "3ph8DsVWF3he"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_response = client.files.create(\n",
        "    file=Path(validation_dataset_file_name),\n",
        "    purpose=\"fine-tune\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "Y0_rouGkF3ez"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_response\n"
      ],
      "metadata": {
        "id": "8t3R-wQKF3b5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_file_id = validation_response.id"
      ],
      "metadata": {
        "id": "3tVZ1zX13IV8"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_file_id"
      ],
      "metadata": {
        "id": "lY_fvLbCHAS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Start a fine-tuning job"
      ],
      "metadata": {
        "id": "d67aKQz_w0pl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.fine_tuning.jobs.create(\n",
        "    model = \"gpt-3.5-turbo\",\n",
        "    training_file = training_file_id,\n",
        "    validation_file = validation_file_id,\n",
        "    suffix=\"samantha-test\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "i3MTc3MoJqY6"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response\n"
      ],
      "metadata": {
        "id": "9Yh8Tf9GJqb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_id = response.id\n",
        "job_id"
      ],
      "metadata": {
        "id": "y4qoXcs7VhPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.fine_tuning.jobs.list(limit=5)\n"
      ],
      "metadata": {
        "id": "YdYbI3UpJXkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " client.fine_tuning.jobs.retrieve('ftjob-NzIn2ZFcLMbctTcgbrvGMfgR')"
      ],
      "metadata": {
        "id": "j2k4z3C9L4xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_response = client.fine_tuning.jobs.list_events(fine_tuning_job_id='ftjob-NzIn2ZFcLMbctTcgbrvGMfgR')"
      ],
      "metadata": {
        "id": "xpRISKenL40i"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_response"
      ],
      "metadata": {
        "id": "VqoYa2FOTXWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "events = job_response.data\n",
        "events"
      ],
      "metadata": {
        "id": "sBFzFGOnL43X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for event in events:\n",
        "  print(event.message)"
      ],
      "metadata": {
        "id": "goz00TbeS42C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating using new model"
      ],
      "metadata": {
        "id": "coDp5s5JW9hk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# getting fine_tune_model name"
      ],
      "metadata": {
        "id": "8kIgum1SWpBe"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.fine_tuning.jobs.retrieve(job_id)\n",
        "\n",
        "#response = client.fine_tuning.jobs.retrieve('ftjob-NzIn2ZFcLMbctTcgbrvGMfgR')\n",
        "response"
      ],
      "metadata": {
        "id": "LfWJMV59TC1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tune_model_id = response.fine_tuned_model\n",
        "fine_tune_model_id\n"
      ],
      "metadata": {
        "id": "QHTrk_N9UA1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_messages = []\n",
        "test_messages.append({\"role\": \"system\", \"content\": system_message})\n",
        "test_message = \"How are you today Samantha?\"\n",
        "\n",
        "test_messages.append({\"role\": \"user\", \"content\": test_message})\n",
        "\n",
        "print(test_messages)"
      ],
      "metadata": {
        "id": "EXzkzYstUA4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model = fine_tune_model_id,\n",
        "    messages = test_messages\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0pHGcuVW7wY",
        "outputId": "cca69cdb-77a4-49f9-dc80-80fa5ec312f8"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thank you for asking! I'm doing quite well, actually. Is there something on your mind that I might be able to help you with?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mNp0RGwyY9pU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}